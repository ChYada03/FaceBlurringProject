# -*- coding: utf-8 -*-
"""FaceBlurring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/142yKajav1VB0cGxI91KYIG2snbxUuZL6
"""

!pip install ultralytics
!pip install supervision huggingface_hub pillow
!pip install mediapipe gradio

"""‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° ‚Üí ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv8 ‚Üí ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å Hugging Face

‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ö‡∏•‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Gaussian Blur, Pixelation ‡πÅ‡∏•‡∏∞ Emoji

‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏û‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ö‡∏•‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‚Üí ‡πÄ‡∏ö‡∏•‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ß‡πâ

‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö UI ‡∏î‡πâ‡∏ß‡∏¢ Gradio ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏•‡∏≠
"""

import cv2 # ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
import numpy as np # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ array ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û
import gradio as gr # ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á UI
from huggingface_hub import hf_hub_download # ‡πÉ‡∏ä‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face
from ultralytics import YOLO # ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv8
from supervision import Detections # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
from PIL import Image, ImageDraw # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û

model_path = hf_hub_download(repo_id="arnabdhar/YOLOv8-Face-Detection", filename="model.pt")
model = YOLO(model_path)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ö‡∏•‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
def blur_face(img, x1, y1, x2, y2, method="gaussian"):
    face = img[y1:y2, x1:x2] # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

    if method == "gaussian":
        face = cv2.GaussianBlur(face, (85, 85), 30) # ‡πÉ‡∏ä‡πâ Gaussian Blur ‡πÄ‡∏ö‡∏•‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    elif method == "pixelation":
        h, w = face.shape[:2]
        temp = cv2.resize(face, (10, 10), interpolation=cv2.INTER_LINEAR)  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 10x10
        face = cv2.resize(temp, (w, h), interpolation=cv2.INTER_NEAREST) # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô pixelation
    elif method == "emoji":
        mask = Image.open("emoji.png").resize((x2 - x1, y2 - y1)) # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏≠‡∏¥‡πÇ‡∏°‡∏à‡∏¥
        img_pil = Image.fromarray(img)
        img_pil.paste(mask, (x1, y1), mask) # ‡∏ß‡∏≤‡∏á png ‡∏ö‡∏ô‡∏†‡∏≤‡∏û
        return np.array(img_pil)

    img[y1:y2, x1:x2] = face # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏•‡∏≠‡πÅ‡∏•‡πâ‡∏ß
    return img

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
def interactive_blur(image, blur_type):
    img = np.array(image) # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô numpy array
    results = model(img) # ‡πÉ‡∏ä‡πâ YOLO ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    detections = Detections.from_ultralytics(results[0]) # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å YOLO
    faces = detections.xyxy.astype(int) # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (x1, y1, x2, y2)

    img_pil = Image.fromarray(img)
    draw = ImageDraw.Draw(img_pil)
    face_list = [] # ‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤(‡πÅ‡∏ö‡∏öIndex)
    face_thumbnails = [] # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö

    for i, (x1, y1, x2, y2) in enumerate(faces):
        draw.rectangle([x1, y1, x2, y2], outline="red", width=3) # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        draw.text((x1, y1 - 10), str(i), fill="red") # ‡πÉ‡∏™‡πà‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ö‡∏ô‡∏†‡∏≤‡∏û

        face_list.append(str(i)) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏•‡∏á‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å

        face_crop = img[y1:y2, x1:x2]
        face_crop = cv2.resize(face_crop, (50, 50)) # ‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_thumbnails.append(Image.fromarray(face_crop)) # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PIL Image

    return img_pil, gr.update(choices=face_list, value=[]), face_thumbnails # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á, ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏•‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
def process_image(image, blur_type, selected_faces):
    img = np.array(image)
    results = model(img) # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
    detections = Detections.from_ultralytics(results[0])
    faces = detections.xyxy.astype(int)

    for idx, (x1, y1, x2, y2) in enumerate(faces):
        if str(idx) not in selected_faces: # ‡πÄ‡∏ö‡∏•‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å

            img = blur_face(img, x1, y1, x2, y2, method=blur_type)

    return Image.fromarray(img) # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏•‡∏≠‡πÅ‡∏•‡πâ‡∏ß

with gr.Blocks() as demo:
    gr.Markdown("# üì∏ Face Blur with YOLOv8 & Gradio") # ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ UI

    image_input = gr.Image(type="pil", label="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û")
    blur_selector = gr.Radio(["gaussian", "pixelation", "emoji"], label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏•‡∏≠", value="gaussian")

    with gr.Row():
        preview = gr.Image(type="pil", label="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö")

    with gr.Row():
        face_selector = gr.CheckboxGroup([], label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ö‡∏•‡∏≠", interactive=True)
        face_gallery = gr.Gallery(label="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤", height=100, columns=5)

    process_btn = gr.Button("üîÑ ‡πÄ‡∏ö‡∏•‡∏≠‡∏†‡∏≤‡∏û")
    final_output = gr.Image(type="pil", label="‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏•‡∏≠‡πÅ‡∏•‡πâ‡∏ß")

    # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û > ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ & ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    image_input.change(
        interactive_blur, inputs=[image_input, blur_selector],
        outputs=[preview, face_selector, face_gallery]
    )

    # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° > ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ö‡∏•‡∏≠‡∏´‡∏ô‡πâ‡∏≤
    process_btn.click(
        process_image, inputs=[image_input, blur_selector, face_selector],
        outputs=final_output
    )
# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Gradio
demo.launch()

import cv2
import mediapipe as mp
from google.colab.patches import cv2_imshow  # ‡πÉ‡∏ä‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô Colab

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Face Detection
mp_face_detection = mp.solutions.face_detection

# ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û
image_path = "people1.jpg"
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ‡πÉ‡∏ä‡πâ Face Detection
with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.3) as face_detection:
    results = face_detection.process(image_rgb)

    if results.detections:
        for detection in results.detections:
            bboxC = detection.location_data.relative_bounding_box
            ih, iw, _ = image.shape
            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

# ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô Colab
cv2_imshow(image)

import matplotlib.pyplot as plt
from huggingface_hub import hf_hub_download
from ultralytics import YOLO
from PIL import Image

model_path = hf_hub_download(repo_id="arnabdhar/YOLOv8-Face-Detection", filename="model.pt")
model = YOLO(model_path)

image_path = "people1.jpg"
image = Image.open(image_path)

output = model(image)

# ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô Detections object
results = Detections.from_ultralytics(output[0])

plt.imshow(output[0].plot())
plt.axis("off")
plt.show()